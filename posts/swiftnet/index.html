<!DOCTYPE html>
<html lang="en-us">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="X-UA-Compatible" content="ie=edge">
	<meta name="theme-color" content="#494f5c">
	<meta name="msapplication-TileColor" content="#494f5c">
<meta itemprop="name" content="Note for paper SwiftNet">
<meta itemprop="description" content="Abstract 许多先前的工作解决了定制轻量级结构的挑战，这些结构通过减少网络的深度，宽度和层的容量来降低计算的复杂度。我们提出了一种可替代的方法，在减少计算代价上达到了显著的效果。第一，我们通过一个通用的轻量级结构来作为识别引擎，之后我们采用一个横向的连接的轻量上采样作为恢复预测分辨率的最经济有效的解决方案。最后，提出了用在多分率下融合共有特征来增加感受野。
Introduction 大多数轻量级的模型从零开始初始化训练，因此丢失了由一些大型数据集提供的知识迁移的机会，这样模型就有相当大的过拟合的风险。一般的模型有两个问题：
 较低的分辨率(一般比输入图像小32倍)导致小目标较难识别 感受野过小对一些大目标难以识别到  有许多技巧可以改善这些问题，如扩张卷积，学习上采样，横向连接和分辨率金字塔等方法，但是并非所有的技巧都适用实时分割。
本文认为基于ImageNet-grade 分类的结构可以权衡模型的精度和速度，我们提出了一种基于共享参数的分辨率金字塔来增加深度模型感受野的新方法。我们的研究表明，通过一个带有横向连接的轻量级编码器，可以有效和准确地提高预测的分辨率。
The proposed segmentation method Basic building blocks 提出了选用ResNet-18和MobileNet V2作为分割的encoders，其中ResNet支持GPU加速更胜一筹
Upsampling decoder 
梯子型的上采样模块有两个输入：低分辨率的特征和来自先前编码器的横向特征
Module for increasing the receptive field 两种可行的增加感受野的方法 1）空间金字塔池化；2）金字塔融合，SPP模块收集编码器在几个池化层产生的特征，并生成具有不同细节级别的表示。该模型SPP block是PSPNet中的简化版本。
Single Scale model 
 黄色梯形代表卷积组，即编码器的部分，在相同的空间分辨率下工作，每个卷积组下采样一次，分辨率下降两倍，最后为H/32xW/32 绿色的SPP(Spatial Pyramid pooling)来增加模型的感受野 编码器特征维数随下采样路径增加，而蓝色上采样层维度不变，所以需要红色模块进行维度统一  Interleaved pyramid fusion model 紧密的编码结构会减小感受野和降低模型容纳能力，提出了一种图像金字塔来解决问题，为了增强梯度在编码器中传播，增加了一个concatenation

Experiment  Adam optimizer learning rate set \(4\times10^{-4}\) decay learning rate with cosine annealing 448x448 crops CamVid  在Cityscapes上的结果">


<meta itemprop="datePublished" content="2020-07-10T10:08:35&#43;08:00" />
<meta itemprop="dateModified" content="2020-07-10T10:08:35&#43;08:00" />
<meta itemprop="wordCount" content="65">



<meta itemprop="keywords" content="untagged," />
<meta property="og:title" content="Note for paper SwiftNet" />
<meta property="og:description" content="Abstract 许多先前的工作解决了定制轻量级结构的挑战，这些结构通过减少网络的深度，宽度和层的容量来降低计算的复杂度。我们提出了一种可替代的方法，在减少计算代价上达到了显著的效果。第一，我们通过一个通用的轻量级结构来作为识别引擎，之后我们采用一个横向的连接的轻量上采样作为恢复预测分辨率的最经济有效的解决方案。最后，提出了用在多分率下融合共有特征来增加感受野。
Introduction 大多数轻量级的模型从零开始初始化训练，因此丢失了由一些大型数据集提供的知识迁移的机会，这样模型就有相当大的过拟合的风险。一般的模型有两个问题：
 较低的分辨率(一般比输入图像小32倍)导致小目标较难识别 感受野过小对一些大目标难以识别到  有许多技巧可以改善这些问题，如扩张卷积，学习上采样，横向连接和分辨率金字塔等方法，但是并非所有的技巧都适用实时分割。
本文认为基于ImageNet-grade 分类的结构可以权衡模型的精度和速度，我们提出了一种基于共享参数的分辨率金字塔来增加深度模型感受野的新方法。我们的研究表明，通过一个带有横向连接的轻量级编码器，可以有效和准确地提高预测的分辨率。
The proposed segmentation method Basic building blocks 提出了选用ResNet-18和MobileNet V2作为分割的encoders，其中ResNet支持GPU加速更胜一筹
Upsampling decoder 
梯子型的上采样模块有两个输入：低分辨率的特征和来自先前编码器的横向特征
Module for increasing the receptive field 两种可行的增加感受野的方法 1）空间金字塔池化；2）金字塔融合，SPP模块收集编码器在几个池化层产生的特征，并生成具有不同细节级别的表示。该模型SPP block是PSPNet中的简化版本。
Single Scale model 
 黄色梯形代表卷积组，即编码器的部分，在相同的空间分辨率下工作，每个卷积组下采样一次，分辨率下降两倍，最后为H/32xW/32 绿色的SPP(Spatial Pyramid pooling)来增加模型的感受野 编码器特征维数随下采样路径增加，而蓝色上采样层维度不变，所以需要红色模块进行维度统一  Interleaved pyramid fusion model 紧密的编码结构会减小感受野和降低模型容纳能力，提出了一种图像金字塔来解决问题，为了增强梯度在编码器中传播，增加了一个concatenation

Experiment  Adam optimizer learning rate set \(4\times10^{-4}\) decay learning rate with cosine annealing 448x448 crops CamVid  在Cityscapes上的结果" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://wuhongyui.github.io/posts/swiftnet/" />
<meta property="article:published_time" content="2020-07-10T10:08:35+08:00" />
<meta property="article:modified_time" content="2020-07-10T10:08:35+08:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Note for paper SwiftNet"/>
<meta name="twitter:description" content="Abstract 许多先前的工作解决了定制轻量级结构的挑战，这些结构通过减少网络的深度，宽度和层的容量来降低计算的复杂度。我们提出了一种可替代的方法，在减少计算代价上达到了显著的效果。第一，我们通过一个通用的轻量级结构来作为识别引擎，之后我们采用一个横向的连接的轻量上采样作为恢复预测分辨率的最经济有效的解决方案。最后，提出了用在多分率下融合共有特征来增加感受野。
Introduction 大多数轻量级的模型从零开始初始化训练，因此丢失了由一些大型数据集提供的知识迁移的机会，这样模型就有相当大的过拟合的风险。一般的模型有两个问题：
 较低的分辨率(一般比输入图像小32倍)导致小目标较难识别 感受野过小对一些大目标难以识别到  有许多技巧可以改善这些问题，如扩张卷积，学习上采样，横向连接和分辨率金字塔等方法，但是并非所有的技巧都适用实时分割。
本文认为基于ImageNet-grade 分类的结构可以权衡模型的精度和速度，我们提出了一种基于共享参数的分辨率金字塔来增加深度模型感受野的新方法。我们的研究表明，通过一个带有横向连接的轻量级编码器，可以有效和准确地提高预测的分辨率。
The proposed segmentation method Basic building blocks 提出了选用ResNet-18和MobileNet V2作为分割的encoders，其中ResNet支持GPU加速更胜一筹
Upsampling decoder 
梯子型的上采样模块有两个输入：低分辨率的特征和来自先前编码器的横向特征
Module for increasing the receptive field 两种可行的增加感受野的方法 1）空间金字塔池化；2）金字塔融合，SPP模块收集编码器在几个池化层产生的特征，并生成具有不同细节级别的表示。该模型SPP block是PSPNet中的简化版本。
Single Scale model 
 黄色梯形代表卷积组，即编码器的部分，在相同的空间分辨率下工作，每个卷积组下采样一次，分辨率下降两倍，最后为H/32xW/32 绿色的SPP(Spatial Pyramid pooling)来增加模型的感受野 编码器特征维数随下采样路径增加，而蓝色上采样层维度不变，所以需要红色模块进行维度统一  Interleaved pyramid fusion model 紧密的编码结构会减小感受野和降低模型容纳能力，提出了一种图像金字塔来解决问题，为了增强梯度在编码器中传播，增加了一个concatenation

Experiment  Adam optimizer learning rate set \(4\times10^{-4}\) decay learning rate with cosine annealing 448x448 crops CamVid  在Cityscapes上的结果"/>

	<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="manifest" href="/site.webmanifest">
	<link rel="mask-icon" href="/safari-pinned-tab.svg" color="">
	<link rel="shortcut icon" href="/favicon.ico">

	<title>Note for paper SwiftNet</title>
	<link rel="stylesheet" href="https://wuhongyui.github.io/css/style.min.657bcb7af31123e4156b1a3d2ff60a636717e54ead74f882136b5114cf72b55e.css" integrity="sha256-ZXvLevMRI+QVaxo9L/YKY2cX5U6tdPiCE2tRFM9ytV4=" crossorigin="anonymous">
	
</head>

<body id="page">
	
<header id="site-header" class="animated slideInUp faster">
		<div class="hdr-wrapper section-inner">
			<div class="hdr-left">
				<div class="site-branding">
					<a href="https://wuhongyui.github.io/">拿了橘子跑</a>
				</div>
				<nav class="site-nav hide-in-mobile">
					
				<a href="https://wuhongyui.github.io/posts/">Article</a>
				<a href="https://wuhongyui.github.io/about-hugo/">About</a>

				</nav>
			</div>
			<div class="hdr-right hdr-icons">
				<span class="hdr-social hide-in-mobile"><a href="https://twitter.com/" target="_blank" rel="noopener me" title="Twitter"><svg xmlns="http://www.w3.org/2000/svg" class="feather" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"></path></svg></a><a href="https://instagram.com/" target="_blank" rel="noopener me" title="Instagram"><svg xmlns="http://www.w3.org/2000/svg" class="feather" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="2" y="2" width="20" height="20" rx="5" ry="5"></rect><path d="M16 11.37A4 4 0 1 1 12.63 8 4 4 0 0 1 16 11.37z"></path><line x1="17.5" y1="6.5" x2="17.5" y2="6.5"></line></svg></a><a href="https://github.com/wuhongyui" target="_blank" rel="noopener me" title="Github"><svg xmlns="http://www.w3.org/2000/svg" class="feather" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></a></span><button id="menu-btn" class="hdr-btn" title="Menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button>
			</div>
		</div>
	</header>
	<div id="mobile-menu" class="animated fast">
		<ul>
			<li><a href="https://wuhongyui.github.io/posts/">Article</a></li>
			<li><a href="https://wuhongyui.github.io/about-hugo/">About</a></li>
		</ul>
	</div>




	<main class="site-main section-inner animated fadeIn faster">
		<article class="thin">
			<header class="post-header">
				<div class="post-meta"><span>Jul 10, 2020</span></div>
				<h1>Note for paper SwiftNet</h1>
			</header>
			<div class="content">
				<h3 id="abstract">Abstract<a href="#abstract" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>

<p>许多先前的工作解决了定制轻量级结构的挑战，这些结构通过减少网络的深度，宽度和层的容量来降低计算的复杂度。我们提出了一种可替代的方法，在减少计算代价上达到了显著的效果。第一，我们通过一个通用的轻量级结构来作为识别引擎，之后我们采用一个横向的连接的轻量上采样作为恢复预测分辨率的最经济有效的解决方案。最后，提出了用在多分率下融合共有特征来增加感受野。</p>

<h3 id="introduction">Introduction<a href="#introduction" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>

<p>大多数轻量级的模型从零开始初始化训练，因此丢失了由一些大型数据集提供的知识迁移的机会，这样模型就有相当大的过拟合的风险。一般的模型有两个问题：</p>

<ol>
<li>较低的分辨率(一般比输入图像小32倍)导致小目标较难识别</li>
<li>感受野过小对一些大目标难以识别到</li>
</ol>

<p>有许多技巧可以改善这些问题，如扩张卷积，学习上采样，横向连接和分辨率金字塔等方法，但是并非所有的技巧都适用实时分割。</p>

<p>本文认为基于ImageNet-grade 分类的结构可以权衡模型的精度和速度，我们提出了一种基于共享参数的分辨率金字塔来增加深度模型感受野的新方法。我们的研究表明，通过一个带有横向连接的轻量级编码器，可以有效和准确地提高预测的分辨率。</p>

<h3 id="the-proposed-segmentation-method">The proposed segmentation method<a href="#the-proposed-segmentation-method" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>

<h4 id="basic-building-blocks">Basic building blocks<a href="#basic-building-blocks" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>

<p>提出了选用ResNet-18和MobileNet V2作为分割的encoders，其中ResNet支持GPU加速更胜一筹</p>

<h4 id="upsampling-decoder">Upsampling decoder<a href="#upsampling-decoder" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>

<p><figure><img src="/images/SwiftNet1.png" alt="解码器结构"></figure></p>

<p>梯子型的上采样模块有两个输入：低分辨率的特征和来自先前编码器的横向特征</p>

<h4 id="module-for-increasing-the-receptive-field">Module for increasing the receptive field<a href="#module-for-increasing-the-receptive-field" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>

<p>两种可行的增加感受野的方法 1）空间金字塔池化；2）金字塔融合，SPP模块收集编码器在几个池化层产生的特征，并生成具有不同细节级别的表示。该模型SPP block是PSPNet中的简化版本。</p>

<h3 id="single-scale-model">Single Scale model<a href="#single-scale-model" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>

<p><figure><img src="/images/SwiftNet2.png" alt="单规模结构"></figure></p>

<ul>
<li>黄色梯形代表卷积组，即编码器的部分，在相同的空间分辨率下工作，每个卷积组下采样一次，分辨率下降两倍，最后为H/32xW/32</li>
<li>绿色的SPP(Spatial Pyramid pooling)来增加模型的感受野</li>
<li>编码器特征维数随下采样路径增加，而蓝色上采样层维度不变，所以需要红色模块进行维度统一</li>
</ul>

<h3 id="interleaved-pyramid-fusion-model">Interleaved pyramid fusion model<a href="#interleaved-pyramid-fusion-model" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>

<p>紧密的编码结构会减小感受野和降低模型容纳能力，提出了一种图像金字塔来解决问题，为了增强梯度在编码器中传播，增加了一个concatenation</p>

<p><figure><img src="/images/SwiftNet3.png" alt="插值金字塔融合结构"></figure></p>

<h3 id="experiment">Experiment<a href="#experiment" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>

<ul>
<li>Adam optimizer</li>
<li>learning rate set <span  class="math">\(4\times10^{-4}\)</span> decay learning rate with cosine annealing</li>
<li>448x448 crops CamVid</li>
</ul>

<p>在Cityscapes上的结果</p>

<p><figure><img src="/images/SwiftNet4.png" alt=""></figure></p>

<p>在CamVid上的对比结果</p>

<p><figure><img src="/images/SwiftNet5.png" alt=""></figure></p>

<h3 id="conclusion">Conclusion<a href="#conclusion" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>

<p>通过 1）设计了比肩ImageNet上的紧凑编码器 2）轻量级的横向跳跃连接解码器；来实现精度和速度的权衡，另外，提出了一种新的交叉金字塔融合方案，它能够进一步提高对靠近摄像机的大物体的检测结果。</p>

			</div>
			<hr class="post-end">
			<footer class="post-info">
				<p>
					<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="https://wuhongyui.github.io/tags/untagged">untagged</a></span>
				</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>65 Words</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>2020-07-10 10:08 &#43;0800</p>
			</footer>
		</article>
		<div class="post-nav thin">
			<a class="next-post" href="https://wuhongyui.github.io/posts/openpose/">
				<span class="post-nav-label"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left"><line x1="19" y1="12" x2="5" y2="12"></line><polyline points="12 19 5 12 12 5"></polyline></svg>&nbsp;Newer</span><br><span>Ubuntu18.04 Openpose Environment configuration</span>
			</a>
			<a class="prev-post" href="https://wuhongyui.github.io/posts/opencv_configuration/">
				<span class="post-nav-label">Older&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><br><span>Opencv Configuration on MacOS</span>
			</a>
		</div>
		<div id="comments" class="thin">
</div>
	</main>

<footer id="site-footer" class="section-inner thin animated fadeIn faster">
		<p>&copy; 2021 <a href="https://wuhongyui.github.io/">拿了橘子跑</a> &#183; <a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC 4.0</a></p>
		<p>
			Made with <a href="https://gohugo.io/" target="_blank" rel="noopener">Wuen</a> &#183; Theme <a href="https://github.com/Track3/hermit" target="_blank" rel="noopener">Hermit</a> &#183; <a href="https://wuhongyui.github.io/posts/index.xml" target="_blank" title="rss"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg></a>
		</p>
	</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>




	<script src="https://wuhongyui.github.io/js/bundle.min.4a9a0ac3d2217822c7865b4161e6c2a71de1d70492264337755427898dd718f6.js" integrity="sha256-SpoKw9IheCLHhltBYebCpx3h1wSSJkM3dVQniY3XGPY=" crossorigin="anonymous"></script>
	

</body>

</html>
